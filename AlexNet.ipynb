{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ff05f0",
   "metadata": {},
   "source": [
    "# Paper\n",
    "- ImageNet Classification with Deep Convolutional Neural Networks(NIPS 2012)\n",
    "- 논문 리뷰 : https://sonstory.tistory.com/41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9cf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from torch.cuda import is_available\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchsummary import torchsummary\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6b0463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a04db",
   "metadata": {},
   "source": [
    "# Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cee8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data Load\n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transformer)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03743ef3",
   "metadata": {},
   "source": [
    "# Calculate Means and Stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f44f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49139965 0.48215845 0.4465309\n",
      "0.20220213 0.19931543 0.20086348\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정규화를 위한 평균, 표준편차 값\n",
    "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in trainset]\n",
    "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in trainset]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])\n",
    "meanG = np.mean([m[1] for m in meanRGB])\n",
    "meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])\n",
    "stdG = np.mean([s[1] for s in stdRGB])\n",
    "stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR, meanG, meanB)\n",
    "print(stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d43bf5",
   "metadata": {},
   "source": [
    "# Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46540d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomResizedCrop(227),\n",
    "                transforms.RandomHorizontalFlip(), # default=0.5\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB]) # 정규화\n",
    "])\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomResizedCrop(227),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2406c2",
   "metadata": {},
   "source": [
    "논문에선 tranformation 이후 이미지의 크기를 224로 지정하지만 이는 오타이며, 227이 맞다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4dd09",
   "metadata": {},
   "source": [
    "# Train and Valid Split\n",
    "https://github.com/JJuOn/pytorch-implementation/blob/main/2.AlexNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc13038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSubset(Dataset):\n",
    "    def __init__(self,Subset,transform=None):\n",
    "        super(CustomSubset,self).__init__()\n",
    "        self.Subset=Subset\n",
    "        self.indices=Subset.indices\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Subset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img,label=self.Subset[idx]\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0dc4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid dataset\n",
    "train_data_len = int(len(trainset)*0.8)\n",
    "valid_data_len = len(trainset) - train_data_len\n",
    "train_data, valid_data = random_split(trainset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90dee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e358a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.transform=None\n",
    "train_data = CustomSubset(train_data, train_transformer)\n",
    "valid_data = CustomSubset(valid_data, test_transformer)\n",
    "\n",
    "test_data.transform = test_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcdb5e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 227, 227]) torch.Size([3, 227, 227]) torch.Size([3, 227, 227])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].size(),valid_data[0][0].size(),test_data[0][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c790df",
   "metadata": {},
   "source": [
    "train, valid, test 데이터셋 모두 transform이 잘 적용된 모습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c07bc",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa8895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl=DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "val_dl=DataLoader(valid_data,batch_size=batch_size,shuffle=False)\n",
    "test_dl=DataLoader(test_data,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae55f932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 227, 227])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "\n",
    "for x,y in val_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "    \n",
    "for x,y in test_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d29e1",
   "metadata": {},
   "source": [
    "# Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf7bc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()# Image input_size=(3, 227, 227)\n",
    "        # Convolutional layer\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11, 11), stride=4, padding=0), \n",
    "            nn.ReLU(), \n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5, 5), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "        )\n",
    "        # FC Layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "        )\n",
    "    \n",
    "    def init_weight(self):\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "        # conv 2,4,5, fc layer -> bias 1\n",
    "        nn.init.constant_(self.net[4].bias, 1)\n",
    "        nn.init.constant_(self.net[10].bias, 1)\n",
    "        nn.init.constant_(self.net[12].bias, 1)\n",
    "        nn.init.constant_(self.classifier[1].bias, 1)\n",
    "        nn.init.constant_(self.classifier[4].bias, 1)\n",
    "        nn.init.constant_(self.classifier[6].bias, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 256 * 6* 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5995f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
      "              ReLU-2           [-1, 96, 55, 55]               0\n",
      " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
      "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-6          [-1, 256, 27, 27]               0\n",
      " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
      "             ReLU-10          [-1, 384, 13, 13]               0\n",
      "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-12          [-1, 384, 13, 13]               0\n",
      "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-14          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
      "          Dropout-16                 [-1, 9216]               0\n",
      "           Linear-17                 [-1, 4096]      37,752,832\n",
      "             ReLU-18                 [-1, 4096]               0\n",
      "          Dropout-19                 [-1, 4096]               0\n",
      "           Linear-20                 [-1, 4096]      16,781,312\n",
      "             ReLU-21                 [-1, 4096]               0\n",
      "           Linear-22                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 58,322,314\n",
      "Trainable params: 58,322,314\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 14.72\n",
      "Params size (MB): 222.48\n",
      "Estimated Total Size (MB): 237.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(num_classes=10).to(device)\n",
    "\n",
    "torchsummary.summary(model, input_size=(3,227,227), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02626b",
   "metadata": {},
   "source": [
    "논문에선 class의 개수가 1000개였지만 CIFAR10의 class 개수는 10이므로 10으로 num_classes 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c60c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): ReLU()\n",
      "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4920d8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2146e-02,  4.9867e-02,  8.8425e-03,  ..., -3.5595e-02,\n",
      "           -4.3241e-02, -5.2277e-02],\n",
      "          [ 5.4961e-03,  2.0416e-02, -2.7046e-02,  ..., -4.0930e-02,\n",
      "           -1.7460e-02,  4.0744e-02],\n",
      "          [-1.7974e-02, -7.7522e-03,  3.3285e-02,  ...,  4.4507e-04,\n",
      "            4.6305e-02,  1.8806e-02],\n",
      "          ...,\n",
      "          [-3.2933e-02, -3.8534e-02,  3.5855e-02,  ...,  4.4763e-02,\n",
      "            4.2090e-02,  9.6921e-03],\n",
      "          [ 4.4572e-02, -9.0005e-03,  2.4313e-02,  ..., -3.1259e-02,\n",
      "            2.0522e-03,  2.9743e-02],\n",
      "          [-1.0890e-03,  2.6189e-02, -3.5394e-02,  ..., -7.9948e-03,\n",
      "            3.5168e-02, -1.3899e-02]],\n",
      "\n",
      "         [[-1.7538e-02, -1.5827e-02,  1.1224e-03,  ...,  1.4050e-02,\n",
      "           -3.7949e-02, -3.6977e-02],\n",
      "          [ 2.4076e-02,  4.4211e-02,  4.9671e-02,  ..., -2.1470e-02,\n",
      "            2.8966e-02, -2.6277e-03],\n",
      "          [-3.1357e-02, -3.7113e-02, -4.1873e-03,  ..., -3.9697e-02,\n",
      "            2.4054e-02,  4.1462e-02],\n",
      "          ...,\n",
      "          [ 3.1165e-02, -1.2951e-02,  1.5831e-02,  ...,  5.8793e-03,\n",
      "           -3.9001e-02, -2.8077e-02],\n",
      "          [ 2.6397e-02, -3.2983e-02,  1.9497e-02,  ...,  2.4858e-02,\n",
      "            3.4391e-02,  2.9058e-02],\n",
      "          [ 1.3813e-02, -3.6404e-02,  5.2115e-02,  ...,  4.3821e-02,\n",
      "            5.2347e-02, -1.1376e-02]],\n",
      "\n",
      "         [[-4.0757e-02, -2.3100e-02,  2.9189e-02,  ..., -2.6575e-02,\n",
      "           -4.6693e-02,  2.4436e-02],\n",
      "          [-4.7579e-02, -4.5097e-02,  2.7685e-02,  ..., -5.1561e-02,\n",
      "           -3.7627e-02, -1.0419e-02],\n",
      "          [-3.4429e-02,  3.1094e-02, -3.4560e-02,  ...,  3.4079e-02,\n",
      "            3.2032e-02,  4.2897e-02],\n",
      "          ...,\n",
      "          [-3.8821e-02,  2.1250e-02, -4.9848e-02,  ..., -4.5730e-02,\n",
      "           -5.2123e-02, -1.4304e-02],\n",
      "          [ 1.0156e-02,  6.1148e-03, -1.2111e-03,  ...,  3.4014e-02,\n",
      "            3.2898e-02, -3.3149e-02],\n",
      "          [ 3.4970e-02, -7.4153e-03, -2.6552e-04,  ...,  5.0694e-02,\n",
      "            4.7154e-02,  3.3188e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4141e-02,  2.6363e-02, -4.9972e-02,  ..., -5.1724e-02,\n",
      "            5.0963e-03, -2.9478e-02],\n",
      "          [-5.1990e-02, -2.5761e-02, -2.1363e-02,  ..., -2.3872e-02,\n",
      "           -2.3640e-02, -5.0723e-02],\n",
      "          [-4.3949e-02, -3.5561e-02, -3.7467e-02,  ..., -3.4346e-02,\n",
      "           -4.4732e-02, -4.2739e-02],\n",
      "          ...,\n",
      "          [ 3.5333e-02,  1.3573e-02,  2.7251e-02,  ..., -4.0897e-02,\n",
      "           -2.0434e-02,  1.9635e-02],\n",
      "          [-2.5085e-02,  1.6261e-02, -3.7865e-02,  ...,  3.6288e-02,\n",
      "           -7.4690e-03, -4.1855e-02],\n",
      "          [ 4.1616e-02, -2.6684e-02,  1.3298e-02,  ...,  1.9510e-02,\n",
      "           -4.7154e-02, -2.2100e-02]],\n",
      "\n",
      "         [[-8.8108e-04, -1.2396e-02,  1.4622e-02,  ..., -2.5202e-02,\n",
      "            4.7167e-02,  2.2288e-02],\n",
      "          [-4.8317e-02,  1.4710e-02,  2.1877e-02,  ..., -5.1279e-02,\n",
      "            1.5277e-02,  1.4764e-02],\n",
      "          [ 2.7688e-02, -1.8407e-02, -4.8000e-02,  ..., -2.8951e-02,\n",
      "           -3.4847e-02, -1.4329e-02],\n",
      "          ...,\n",
      "          [ 3.8834e-02,  1.6723e-02,  5.4455e-03,  ...,  2.1349e-02,\n",
      "           -4.2454e-02,  2.4570e-02],\n",
      "          [ 5.6879e-03,  2.1295e-03,  4.3891e-02,  ...,  5.0962e-02,\n",
      "           -3.9705e-02,  1.3551e-02],\n",
      "          [ 6.0208e-03, -4.2399e-03,  3.7776e-02,  ..., -2.1331e-02,\n",
      "           -2.1955e-02,  3.4432e-02]],\n",
      "\n",
      "         [[ 2.0276e-02,  2.2406e-03, -9.2117e-03,  ...,  4.8745e-02,\n",
      "            2.4880e-02,  4.5767e-02],\n",
      "          [-4.8731e-02,  3.5547e-02,  5.0215e-02,  ...,  3.9631e-04,\n",
      "           -3.1014e-02, -2.5830e-02],\n",
      "          [-2.4920e-02, -4.4633e-02, -3.1074e-02,  ...,  2.0462e-02,\n",
      "           -5.9785e-03, -3.2871e-02],\n",
      "          ...,\n",
      "          [-7.4159e-03, -3.4444e-02, -5.0883e-02,  ..., -4.7232e-02,\n",
      "           -1.4737e-02,  3.4656e-02],\n",
      "          [ 2.6529e-03,  2.2478e-02,  1.0211e-03,  ..., -1.4520e-02,\n",
      "           -1.9882e-02, -7.3134e-04],\n",
      "          [ 4.0946e-02, -4.4487e-03, -1.2466e-02,  ..., -4.3012e-03,\n",
      "            9.5789e-03,  2.7384e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7980e-02, -2.5323e-02,  1.3244e-02,  ..., -2.4658e-02,\n",
      "           -2.6220e-02,  4.1740e-02],\n",
      "          [ 1.8946e-02, -2.3360e-02,  3.4198e-02,  ..., -3.3127e-02,\n",
      "           -4.5007e-02, -3.0417e-02],\n",
      "          [-5.0787e-02,  3.4234e-02, -1.4744e-02,  ...,  6.5655e-03,\n",
      "           -5.4458e-03,  1.6552e-02],\n",
      "          ...,\n",
      "          [-4.0359e-02,  3.4162e-02, -5.1346e-02,  ...,  4.9508e-02,\n",
      "            1.7867e-02, -4.7010e-02],\n",
      "          [-1.2605e-02,  2.7109e-03, -8.1200e-03,  ...,  5.7869e-03,\n",
      "            2.7569e-02,  9.7118e-03],\n",
      "          [-3.5409e-02, -3.6669e-03, -1.9862e-02,  ..., -6.2437e-03,\n",
      "           -3.4717e-02, -5.0237e-02]],\n",
      "\n",
      "         [[-5.3560e-03,  8.7272e-03, -3.3533e-02,  ..., -3.1678e-02,\n",
      "            7.1154e-03, -1.4377e-02],\n",
      "          [-2.9064e-02, -3.1654e-05, -3.9966e-02,  ..., -4.2005e-02,\n",
      "            5.1515e-02, -4.2208e-02],\n",
      "          [ 1.6098e-02,  5.1245e-02, -3.5888e-02,  ..., -3.3827e-02,\n",
      "           -1.9966e-02,  3.3688e-03],\n",
      "          ...,\n",
      "          [-2.2411e-02, -2.9025e-02, -4.4295e-03,  ...,  1.0733e-02,\n",
      "            1.9375e-02, -4.7823e-02],\n",
      "          [ 5.0789e-02,  8.2410e-03, -2.4513e-02,  ..., -1.9871e-02,\n",
      "           -3.7808e-04,  6.7424e-03],\n",
      "          [-5.0777e-02,  4.4992e-02, -1.4884e-02,  ...,  1.8939e-02,\n",
      "           -2.0733e-02, -4.9866e-02]],\n",
      "\n",
      "         [[ 4.2968e-02, -3.7818e-02, -3.0536e-04,  ...,  3.7774e-02,\n",
      "           -3.4514e-02,  1.3031e-02],\n",
      "          [-5.1786e-02, -1.0052e-02, -1.2072e-02,  ...,  4.9243e-02,\n",
      "           -1.4186e-02,  1.2747e-02],\n",
      "          [-1.7277e-02,  3.1102e-02,  4.0775e-02,  ..., -4.0295e-02,\n",
      "           -1.9207e-02,  4.5529e-02],\n",
      "          ...,\n",
      "          [ 1.8971e-02, -6.1432e-04,  4.6074e-02,  ...,  3.4609e-03,\n",
      "            3.3314e-02, -1.6582e-02],\n",
      "          [ 1.8008e-02, -2.7320e-02,  2.2274e-02,  ..., -3.3155e-02,\n",
      "            1.5036e-02, -4.4755e-02],\n",
      "          [ 1.8562e-02, -2.8026e-02,  4.2095e-02,  ..., -1.8409e-02,\n",
      "            1.9069e-03,  1.5856e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1802e-02,  3.6059e-02, -7.9124e-03,  ..., -1.3665e-03,\n",
      "            3.8623e-02,  3.0589e-03],\n",
      "          [ 2.9723e-02, -3.3821e-02, -8.8455e-03,  ...,  2.8408e-02,\n",
      "           -3.2130e-02, -1.3902e-02],\n",
      "          [-3.7664e-02,  9.5448e-03,  4.7038e-02,  ..., -1.9727e-02,\n",
      "            3.6460e-02, -3.6400e-02],\n",
      "          ...,\n",
      "          [ 1.0918e-03, -2.2958e-02, -3.0552e-03,  ...,  4.1444e-03,\n",
      "           -4.7940e-02, -2.5982e-02],\n",
      "          [ 2.9464e-02, -4.8156e-02, -3.4541e-02,  ..., -2.9639e-02,\n",
      "           -2.8885e-02, -2.7604e-02],\n",
      "          [ 4.3744e-02,  4.1533e-02,  1.3709e-02,  ...,  3.8177e-02,\n",
      "            4.2080e-02, -3.2450e-02]],\n",
      "\n",
      "         [[-2.6860e-02, -5.2479e-02, -1.9672e-02,  ..., -3.9529e-02,\n",
      "            3.6333e-02,  1.6722e-02],\n",
      "          [ 4.3407e-02, -6.3379e-03,  1.1464e-02,  ...,  4.9674e-02,\n",
      "            5.5540e-03,  1.8469e-03],\n",
      "          [ 1.4499e-02,  4.0243e-02,  1.8001e-02,  ..., -5.0265e-02,\n",
      "           -5.0664e-02, -2.6213e-02],\n",
      "          ...,\n",
      "          [ 3.7883e-02,  3.2814e-02,  5.0833e-04,  ..., -2.6043e-02,\n",
      "            9.8691e-03, -8.1161e-03],\n",
      "          [-5.0286e-02, -3.0973e-02, -4.4231e-02,  ...,  1.3365e-02,\n",
      "            1.6838e-02,  2.5691e-02],\n",
      "          [ 2.0336e-02, -4.5266e-02,  6.7025e-03,  ..., -4.5262e-02,\n",
      "            1.4992e-03,  4.6434e-02]],\n",
      "\n",
      "         [[ 3.4781e-02,  2.1814e-02,  3.0353e-02,  ..., -1.9010e-04,\n",
      "           -5.1188e-02, -7.6862e-03],\n",
      "          [ 3.0497e-02,  3.8335e-02, -3.7111e-02,  ...,  1.0922e-03,\n",
      "           -4.7727e-02,  2.1889e-03],\n",
      "          [-1.2815e-02,  3.1550e-02, -3.6679e-02,  ..., -1.2582e-02,\n",
      "            2.8970e-02, -4.3391e-02],\n",
      "          ...,\n",
      "          [ 1.5412e-03,  2.4187e-02, -8.7988e-03,  ...,  4.4386e-02,\n",
      "            2.4777e-02,  2.1489e-04],\n",
      "          [ 1.2146e-02, -2.0436e-02, -6.8797e-03,  ..., -1.0276e-02,\n",
      "            3.0847e-02,  4.9050e-02],\n",
      "          [ 5.0813e-02, -2.3992e-02,  4.1303e-03,  ..., -4.2971e-02,\n",
      "           -5.1288e-02,  6.9012e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7753e-02, -4.1680e-02,  1.5085e-02,  ...,  1.3909e-02,\n",
      "            4.0712e-02, -3.5044e-05],\n",
      "          [ 1.4417e-02,  4.1495e-02, -4.0195e-03,  ...,  3.9814e-02,\n",
      "            4.9586e-02,  4.2462e-02],\n",
      "          [-1.7799e-03,  3.1360e-02,  4.1340e-02,  ..., -1.8882e-02,\n",
      "           -2.3535e-02, -4.1883e-02],\n",
      "          ...,\n",
      "          [-5.1263e-02, -3.1519e-02,  1.2447e-02,  ...,  4.8569e-02,\n",
      "           -9.1974e-03,  3.2874e-03],\n",
      "          [-1.3258e-02, -3.0495e-03,  7.9776e-03,  ...,  1.6140e-02,\n",
      "           -3.9639e-02,  4.0522e-02],\n",
      "          [-3.5970e-02,  4.6556e-03, -5.1946e-02,  ..., -4.5867e-02,\n",
      "            2.8784e-02, -8.0482e-03]],\n",
      "\n",
      "         [[-4.6914e-02,  5.0965e-02, -4.4323e-02,  ..., -4.8973e-02,\n",
      "           -3.3833e-02, -2.7117e-02],\n",
      "          [ 1.5741e-02,  1.0019e-02, -3.6150e-04,  ..., -3.0470e-03,\n",
      "           -5.1611e-02, -5.0381e-02],\n",
      "          [-3.1901e-02, -3.7667e-02,  3.0965e-02,  ...,  2.6911e-02,\n",
      "            3.6741e-02, -5.0900e-02],\n",
      "          ...,\n",
      "          [ 5.0653e-02,  4.1442e-02,  3.0061e-02,  ...,  3.3133e-02,\n",
      "           -4.6802e-02, -8.4229e-03],\n",
      "          [ 2.2356e-02,  1.5007e-02,  1.4801e-02,  ..., -2.7150e-02,\n",
      "            4.8338e-02, -1.0677e-04],\n",
      "          [-4.8129e-02, -2.8313e-02, -4.4578e-02,  ..., -4.5468e-02,\n",
      "           -3.4482e-02,  4.4724e-02]],\n",
      "\n",
      "         [[-7.2672e-03, -2.6821e-02, -8.4802e-03,  ...,  2.8072e-02,\n",
      "           -4.9955e-02, -4.5350e-02],\n",
      "          [-1.2007e-04, -2.7701e-03, -3.1613e-02,  ...,  5.1846e-02,\n",
      "            4.5880e-02,  4.6871e-02],\n",
      "          [-2.1139e-03,  2.6371e-02, -5.2202e-02,  ...,  7.2303e-03,\n",
      "            5.4464e-03,  3.4226e-02],\n",
      "          ...,\n",
      "          [ 2.9615e-02, -2.4667e-02, -4.5848e-02,  ...,  4.1199e-03,\n",
      "            4.8645e-02, -3.2231e-02],\n",
      "          [-2.4698e-02, -4.9225e-02,  3.2693e-02,  ..., -1.2642e-02,\n",
      "           -4.8292e-02,  3.9085e-03],\n",
      "          [-2.8111e-02,  1.2112e-02,  5.1451e-02,  ..., -4.8252e-02,\n",
      "            1.0921e-02,  4.2082e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8658e-02, -2.1736e-02, -1.0758e-02,  ..., -1.5270e-02,\n",
      "           -2.0044e-02,  3.2179e-02],\n",
      "          [-1.3556e-02,  1.2575e-02,  3.9293e-02,  ..., -9.5764e-03,\n",
      "           -4.8156e-02,  2.6020e-02],\n",
      "          [-2.2655e-02,  3.5315e-02, -4.3133e-02,  ...,  1.9744e-02,\n",
      "           -3.7459e-02,  3.5758e-02],\n",
      "          ...,\n",
      "          [-1.7403e-02, -2.9060e-02,  4.4987e-02,  ..., -3.6672e-02,\n",
      "           -4.2905e-02, -2.6816e-02],\n",
      "          [-4.6175e-02,  4.8509e-02, -3.6011e-02,  ...,  2.9004e-02,\n",
      "            5.2238e-04, -3.8604e-02],\n",
      "          [-1.7387e-02,  3.0341e-02,  1.4398e-02,  ...,  3.7325e-02,\n",
      "           -2.5564e-03, -4.3469e-02]],\n",
      "\n",
      "         [[-3.7616e-02, -4.2445e-02, -6.6273e-03,  ...,  2.5717e-02,\n",
      "            5.0618e-02,  2.5013e-02],\n",
      "          [ 3.2289e-04, -4.4641e-02, -1.4819e-02,  ...,  4.3381e-02,\n",
      "           -4.3585e-02, -2.3627e-02],\n",
      "          [ 3.5818e-02,  2.3490e-02,  1.5933e-02,  ...,  2.1026e-04,\n",
      "            1.8421e-02,  3.1984e-03],\n",
      "          ...,\n",
      "          [ 3.0016e-02,  3.7253e-02, -1.9458e-02,  ..., -4.6314e-02,\n",
      "            3.4399e-02, -4.2542e-02],\n",
      "          [ 3.3097e-02,  3.4228e-02, -2.2652e-03,  ..., -4.0438e-03,\n",
      "           -2.9107e-02,  5.0322e-04],\n",
      "          [ 6.8280e-04,  2.4732e-03, -5.0131e-02,  ..., -1.7918e-02,\n",
      "           -1.9962e-02, -5.1025e-02]],\n",
      "\n",
      "         [[ 8.7811e-03, -2.6113e-02,  5.2013e-02,  ...,  8.6237e-05,\n",
      "            6.7336e-03, -3.9298e-02],\n",
      "          [ 5.0667e-02,  2.2242e-02,  4.5039e-02,  ...,  2.4832e-02,\n",
      "           -7.5398e-03, -4.4351e-02],\n",
      "          [-5.8083e-03, -2.0237e-02,  1.3110e-02,  ..., -7.0402e-03,\n",
      "            1.7916e-02, -4.0994e-03],\n",
      "          ...,\n",
      "          [-4.4064e-02,  3.2060e-02,  3.8389e-02,  ...,  5.7299e-03,\n",
      "           -3.5610e-02, -5.1416e-02],\n",
      "          [ 3.7313e-02,  2.0713e-02,  3.3939e-02,  ..., -2.1693e-02,\n",
      "           -1.6042e-02, -1.3726e-02],\n",
      "          [ 5.1405e-02,  3.2366e-02,  4.2992e-02,  ...,  2.0664e-02,\n",
      "            4.1709e-02,  3.1364e-02]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 가중치 초기화 확인\n",
    "for p in model.parameters():\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee915fa7",
   "metadata": {},
   "source": [
    "# Optimizer & Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40f874fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1738c7c",
   "metadata": {},
   "source": [
    "# Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f681d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_size = 0\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    prograss_bar = tqdm(data_loader)\n",
    "    \n",
    "    for batch_idx, (img, lbl) in enumerate(prograss_bar, start=1):\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterion(output, lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = output.max(dim=1)\n",
    "        corr += pred.eq(lbl).sum().item()\n",
    "        running_loss += loss.item() * img.size(0)\n",
    "        running_size += img.size(0)\n",
    "        prograss_bar.set_description(f'[Training] loss: {running_loss / running_size:.4f}, accuracy: {corr / running_size:.4f}')\n",
    "        \n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aa1feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        for img, lbl in data_loader:\n",
    "            img, lbl = img.to(device), lbl.to(device)\n",
    "            output = model(img)\n",
    "            _, pred = output.max(dim=1)\n",
    "            corr += torch.sum(pred.eq(lbl)).item()\n",
    "            running_loss += criterion(output, lbl).item() * img.size(0)\n",
    "            \n",
    "        acc = corr / len(data_loader.dataset)\n",
    "  \n",
    "        return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3884d69f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.3024, accuracy: 0.1017: 100%|███████████████████████████████████| 1250/1250 [01:13<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 2.30149. Saving Model!\n",
      "epoch 01, loss: 2.30238, acc: 0.10172, val_loss: 2.30149, val_accuracy: 0.10380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.2633, accuracy: 0.1374: 100%|███████████████████████████████████| 1250/1250 [02:21<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.30149 to 2.13862. Saving Model!\n",
      "epoch 02, loss: 2.26331, acc: 0.13737, val_loss: 2.13862, val_accuracy: 0.20770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 2.0508, accuracy: 0.2227: 100%|███████████████████████████████████| 1250/1250 [03:58<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 2.13862 to 1.98977. Saving Model!\n",
      "epoch 03, loss: 2.05082, acc: 0.22270, val_loss: 1.98977, val_accuracy: 0.24130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.8975, accuracy: 0.2819: 100%|███████████████████████████████████| 1250/1250 [03:33<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.98977 to 1.82526. Saving Model!\n",
      "epoch 04, loss: 1.89755, acc: 0.28190, val_loss: 1.82526, val_accuracy: 0.32030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.8023, accuracy: 0.3210: 100%|███████████████████████████████████| 1250/1250 [03:25<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.82526 to 1.75214. Saving Model!\n",
      "epoch 05, loss: 1.80229, acc: 0.32095, val_loss: 1.75214, val_accuracy: 0.34990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.7449, accuracy: 0.3462: 100%|███████████████████████████████████| 1250/1250 [02:05<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.75214 to 1.66182. Saving Model!\n",
      "epoch 06, loss: 1.74488, acc: 0.34623, val_loss: 1.66182, val_accuracy: 0.38560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.6862, accuracy: 0.3700: 100%|███████████████████████████████████| 1250/1250 [02:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.66182 to 1.65720. Saving Model!\n",
      "epoch 07, loss: 1.68622, acc: 0.37005, val_loss: 1.65720, val_accuracy: 0.38330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.6456, accuracy: 0.3874: 100%|███████████████████████████████████| 1250/1250 [02:06<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.65720 to 1.62408. Saving Model!\n",
      "epoch 08, loss: 1.64563, acc: 0.38740, val_loss: 1.62408, val_accuracy: 0.40160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.6103, accuracy: 0.4002: 100%|███████████████████████████████████| 1250/1250 [02:02<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.62408 to 1.55039. Saving Model!\n",
      "epoch 09, loss: 1.61027, acc: 0.40018, val_loss: 1.55039, val_accuracy: 0.43710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.5676, accuracy: 0.4216: 100%|███████████████████████████████████| 1250/1250 [02:01<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 1.56764, acc: 0.42163, val_loss: 1.68114, val_accuracy: 0.40620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.5186, accuracy: 0.4411: 100%|███████████████████████████████████| 1250/1250 [02:00<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.55039 to 1.48384. Saving Model!\n",
      "epoch 11, loss: 1.51857, acc: 0.44110, val_loss: 1.48384, val_accuracy: 0.45660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.4714, accuracy: 0.4613: 100%|███████████████████████████████████| 1250/1250 [02:09<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.48384 to 1.45250. Saving Model!\n",
      "epoch 12, loss: 1.47142, acc: 0.46130, val_loss: 1.45250, val_accuracy: 0.47360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.4365, accuracy: 0.4795: 100%|███████████████████████████████████| 1250/1250 [02:01<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.45250 to 1.43068. Saving Model!\n",
      "epoch 13, loss: 1.43652, acc: 0.47947, val_loss: 1.43068, val_accuracy: 0.48420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3986, accuracy: 0.4912: 100%|███████████████████████████████████| 1250/1250 [02:03<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.43068 to 1.33891. Saving Model!\n",
      "epoch 14, loss: 1.39864, acc: 0.49120, val_loss: 1.33891, val_accuracy: 0.51530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3664, accuracy: 0.5057: 100%|███████████████████████████████████| 1250/1250 [01:57<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.33891 to 1.31911. Saving Model!\n",
      "epoch 15, loss: 1.36641, acc: 0.50567, val_loss: 1.31911, val_accuracy: 0.53080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.3218, accuracy: 0.5253: 100%|███████████████████████████████████| 1250/1250 [02:00<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.31911 to 1.26387. Saving Model!\n",
      "epoch 16, loss: 1.32182, acc: 0.52533, val_loss: 1.26387, val_accuracy: 0.54400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2856, accuracy: 0.5383: 100%|███████████████████████████████████| 1250/1250 [02:06<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 1.28565, acc: 0.53830, val_loss: 1.26633, val_accuracy: 0.54230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2491, accuracy: 0.5523: 100%|███████████████████████████████████| 1250/1250 [01:59<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.26387 to 1.21660. Saving Model!\n",
      "epoch 18, loss: 1.24910, acc: 0.55230, val_loss: 1.21660, val_accuracy: 0.56530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.2228, accuracy: 0.5609: 100%|███████████████████████████████████| 1250/1250 [01:57<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.21660 to 1.14967. Saving Model!\n",
      "epoch 19, loss: 1.22277, acc: 0.56088, val_loss: 1.14967, val_accuracy: 0.58720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1815, accuracy: 0.5777: 100%|███████████████████████████████████| 1250/1250 [01:59<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 1.18152, acc: 0.57768, val_loss: 1.18706, val_accuracy: 0.57590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1631, accuracy: 0.5854: 100%|███████████████████████████████████| 1250/1250 [02:06<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.14967 to 1.11022. Saving Model!\n",
      "epoch 21, loss: 1.16315, acc: 0.58537, val_loss: 1.11022, val_accuracy: 0.59350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1222, accuracy: 0.6001: 100%|███████████████████████████████████| 1250/1250 [02:05<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.11022 to 1.09565. Saving Model!\n",
      "epoch 22, loss: 1.12221, acc: 0.60010, val_loss: 1.09565, val_accuracy: 0.60790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.1091, accuracy: 0.6053: 100%|███████████████████████████████████| 1250/1250 [02:15<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.09565 to 1.08279. Saving Model!\n",
      "epoch 23, loss: 1.10909, acc: 0.60530, val_loss: 1.08279, val_accuracy: 0.61510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0764, accuracy: 0.6149: 100%|███████████████████████████████████| 1250/1250 [02:40<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.08279 to 1.06557. Saving Model!\n",
      "epoch 24, loss: 1.07639, acc: 0.61493, val_loss: 1.06557, val_accuracy: 0.61980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0602, accuracy: 0.6229: 100%|███████████████████████████████████| 1250/1250 [02:09<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 1.06023, acc: 0.62285, val_loss: 1.12915, val_accuracy: 0.59790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0467, accuracy: 0.6303: 100%|███████████████████████████████████| 1250/1250 [02:21<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.06557 to 1.02332. Saving Model!\n",
      "epoch 26, loss: 1.04671, acc: 0.63033, val_loss: 1.02332, val_accuracy: 0.63510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0196, accuracy: 0.6399: 100%|███████████████████████████████████| 1250/1250 [01:58<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.02332 to 0.98454. Saving Model!\n",
      "epoch 27, loss: 1.01963, acc: 0.63990, val_loss: 0.98454, val_accuracy: 0.65470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 1.0045, accuracy: 0.6425: 100%|███████████████████████████████████| 1250/1250 [01:53<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 0.98454 to 0.97538. Saving Model!\n",
      "epoch 28, loss: 1.00446, acc: 0.64250, val_loss: 0.97538, val_accuracy: 0.65360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9816, accuracy: 0.6530: 100%|███████████████████████████████████| 1250/1250 [02:23<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 0.97538 to 0.96035. Saving Model!\n",
      "epoch 29, loss: 0.98159, acc: 0.65297, val_loss: 0.96035, val_accuracy: 0.65700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training] loss: 0.9575, accuracy: 0.6631: 100%|███████████████████████████████████| 1250/1250 [02:28<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, loss: 0.95749, acc: 0.66310, val_loss: 0.97508, val_accuracy: 0.65380\n"
     ]
    }
   ],
   "source": [
    "min_loss = np.inf\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Model Training\n",
    "    train_loss, train_acc = model_train(model, train_dl, criterion, optimizer, device)\n",
    "    val_loss, val_acc = model_evaluate(model, val_dl, criterion, device)   \n",
    "    \n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), './model/AlexNet.pth')\n",
    "\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c967d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e7e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/AlexNet.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83ad6dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation loss: 0.97061, evaluation accuracy: 0.65230\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model_evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "print(f'evaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfbed2",
   "metadata": {},
   "source": [
    "##### Reference\n",
    "- https://teddylee777.github.io/pytorch/alexnet-implementation/\n",
    "- https://github.com/JJuOn/pytorch-implementation/blob/main/2.AlexNet.ipynb\n",
    "- https://deep-learning-study.tistory.com/518"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
